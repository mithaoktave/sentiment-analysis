# -*- coding: utf-8 -*-
"""codebarulagi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dAhnnt_jIjt-9i7HbbSnvuIcZpLSjPZL

##**Import Library**
"""

!pip install Sastrawi

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import make_scorer
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from typing import Tuple
import copy as cp

import warnings
warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/gdrive')

"""##**Load Dataset**"""

# Mengakses dataset
df = pd.read_excel('/content/gdrive/MyDrive/Riset/data-label.xlsx')
df.head()

df['Label'].value_counts()

# Mengecek data kosong
df.isnull().sum()

# Melihat dimensi data
df.shape

df['Review'].iloc[1]

df_copy = df.copy()

"""##**Preprocessing Data**

###**Cleaning Data**
"""

def clean(text):
  # Menghapus newline
  text = text.replace('\n', ' ')

  # Menghapus non-ascii
  text = text.encode('ascii', 'ignore').decode('utf-8', 'ignore')

  # Menghapus tanda baca
  text = re.sub('\w+:\/\/\S+', '', text)
  text = re.sub('\[.*?\]', ' ', text)
  text = re.sub('[^a-zA-Z]', ' ', text)

  # Menghapus white space
  text = re.sub('[\s]+', ' ', text)

  return text

df['Review'] = df['Review'].apply(clean)
df['Review'].head()

"""###**Case Folding**"""

def case_folding(text):
  text = text.lower()
  return text

df['Review'] = df['Review'].apply(case_folding)
df['Review'].head()

"""###**Tokenizing**"""

nltk.download('punkt')
def tokenizer(text):
  return word_tokenize(text)

df['Review'] = df['Review'].apply(tokenizer)
df['Review'].head(20)

"""###**Stopword**"""

nltk.download('stopwords')
list_stopword = stopwords.words('indonesian')

# Menambahkan kata yang perlu dihapus
list_stopword.extend(['yg', 'n', 'nan', 'and', 'dn','ter', 'dgn', 'lho', 'ter',
                      'per', 't', 'gaes', 'D', 'd','gan', 'for', 'dll', 'pd', 'g',
                      'deh', 'sd', 'cuy', 'nya', 'sih', 'nih','lan','bal', 'gc',
                      'bngat', 'bngt', 'brow', 'sihni', 'bray', 'ya', 'i', 'bo',
                      'ft', 'rb', 'jd', 'tp', 'utk', 'lg', 'lh', 'x', 'nd', 'bwt',
                      'tpi', 'cb', 'cuk', 'njim', 'iam', 'mah', 'y', 'xg', 'lgi',
                      'mw', 'gan', 'krna', 'untk', 'dsb','dah', 'si', 'gw', 'in',
                      'poolll', 'sbg', 'rem', 'yah', 'k', 'bgt', 'bs', 'dg','kl',
                      'jg', 'tuk', 'tpie', 'ama', 'msh', 'tidak bagus', 'tidak bagus',
                      'tidak bersih', 'kurang banyak', 'tapi sayang', 'tidak senang', 'tidak cocok'])

list_stopword = set(list_stopword)

def stopword(words):
  return [word for word in words if word not in list_stopword]

# Daftar kata pada corpus nltk dan tambahan
list_stopword

df['Review'] = df['Review'].apply(stopword)
df['Review'].head()

df['Review'].to_csv('datastopword1.csv')

"""###**Konversi Slangword**"""

# mengakses dataset kamus
slang_dictionary = pd.read_csv('/content/gdrive/MyDrive/Riset/kamus_slangword.txt',
                               sep=';',
                               header=None,
                               names=['slang', 'formal'])
slang_dictionary.head()

# Mengkonversi menjadi dictionary
slang_dict = pd.Series(slang_dictionary['formal'].values,
                       index=slang_dictionary['slang']).to_dict()

# Membuat fungsi slangwords
def Slangwords(text):
    for word in text:
      if word in slang_dict.keys():
        text = list(map(lambda x: x.replace(word, slang_dict[word]), text))
    return text

# Terapkan fungsi diatas
df['Review'] = df['Review'].apply(Slangwords)
df['Review'].head()

df['Review'].to_csv('dataslangword1.csv')

"""###**Stemming**"""

# Membuat stemmer
factory = StemmerFactory()
stemmer = factory.create_stemmer()

def stemming(term):
  return stemmer.stem(term)

term_dict = {}

for doc in df['Review']:
  for term in doc:
    if term not in term_dict:
      term_dict[term] = ' '

print(len(term_dict))
print('------------------------------')

for term in term_dict:
  term_dict[term] = stemming(term)
  print(term, ':', term_dict[term])

# Stemming ke dataframe
def get_stemm(doc):
  return [term_dict[term] for term in doc]

df['Review'] = df['Review'].apply(get_stemm)
df['Review'].head()

"""###**Feature Selection**"""

# Menghapus kolom yang tidak digunakan
df_clean = df.drop(columns=['Nama', 'Waktu', 'Rating'])
df_clean.head()

# Visualisasi persentase label
fig, ax = plt.subplots(figsize = (4, 4))
sizes = [count for count in df_clean['Label'].value_counts()]
labels = ["Positif", "Negatif", "Netral"]
explode = (0.1, 0, 0)
colors = ['#66b3ff', '#ffcc99', '#ff9999']
ax.pie(x=sizes,
       labels=labels,
       colors=colors,
       autopct='%1.1f%%',
       explode=explode,
       textprops={'fontsize': 14})
ax.set_title('Persentasi Label', fontsize = 15, pad = 20)
plt.show()

"""###**Encoding Data Target**"""

# Melakukan encoding terhadap label
df_clean['Label'] = df_clean['Label'].astype('category')
df_clean['Label'] = df_clean['Label'].cat.codes
df_clean.head()

df_clean['Label'].unique()

"""*   0 = Negative
*   1 = Neutral
*   2 = Positive

###**TF-IDF**
"""

# konversi list ke string
def convert_text(texts):
  return ' '.join([text for text in texts])

df_clean['review'] = df_clean['Review'].apply(convert_text)
df_clean['review'].head()

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
response = vectorizer.fit_transform(df_clean['review'])
print(response)

"""**Membuat dataframe agar lebih mudah melihat setiap token pada data**.
<br/>
Note: Dataframe dibawah ini tidak ada hubungan/pengaruh terhadap model atau code lain.
"""

pd.set_option('display.max_columns', None)

# Bobot keseluruhan data
df_tfidf = pd.DataFrame(response.todense().T,
                        index=vectorizer.get_feature_names_out(),
                        columns=[f'D{i+1}' for i in range(len(df_clean['review']))])

df_tfidf.head()

# Bobot data baris pertama atau index ke 0
df_tfidf1 = pd.DataFrame(response[0].todense().T,
                        index=vectorizer.get_feature_names_out(),
                        columns=['tfidf'])
df_tfidf1.sort_values(by=['tfidf'], ascending=False).head(25)

"""###**Menentukan Variabel**"""

# Menentukan variabel independen dan variabel target
X = response
y = df_clean['Label']
print(X.shape,y.shape)

df_clean['Label'].unique()

"""##**Modeling**

**Membuat Fungsi Classification Report**
"""

def classification_report_with_accuracy_score(y_true, y_pred):
  print(classification_report(y_true, y_pred))
  return accuracy_score(y_true, y_pred)

"""**Membuat Fungsi Confusion Matrix**"""

def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array) -> Tuple[np.array, np.array, np.array]:

    model_ = cp.deepcopy(model)
    no_classes = len(np.unique(y))
    actual_classes = np.empty([0], dtype=int)
    predicted_classes = np.empty([0], dtype=int)
    predicted_proba = np.empty([0, no_classes])

    for train_ndx, test_ndx in kfold.split(X):
        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]
        actual_classes = np.append(actual_classes, test_y)
        model_.fit(train_X, train_y)
        predicted_classes = np.append(predicted_classes, model_.predict(test_X))
        try:
            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)
        except:
            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)
    return actual_classes, predicted_classes, predicted_proba

def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array, sorted_labels : list):

    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)
    plt.figure(figsize=(6,5))
    sns.heatmap(matrix,
                annot=True,
                xticklabels=sorted_labels,
                yticklabels=sorted_labels,
                cmap="Blues",
                fmt="g")
    plt.xlabel('Predicted');
    plt.ylabel('Actual');
    plt.title('Confusion Matrix')
    plt.show()

"""###**Pengujian Jumlah Tree**

####**Jumlah Tree = 100**
"""

model_tree_100 = RandomForestClassifier(n_estimators=100,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_tree_100 = cross_val_score(model_tree_100, X, y, cv=cv,
                                  scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_tree_100)
print('Rata-rata akurasi :', scores_tree_100.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_tree_100, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Jumlah Tree = 200**"""

model_tree_200 = RandomForestClassifier(n_estimators=200,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_tree_200 = cross_val_score(model_tree_200, X, y, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_tree_200)
print('Rata-rata akurasi :', scores_tree_200.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_tree_200, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Jumlah Tree = 300**"""

model_tree_300 = RandomForestClassifier(n_estimators=300,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_tree_300 = cross_val_score(model_tree_300, X, y, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_tree_300)
print('Rata-rata akurasi :', scores_tree_300.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_tree_300, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""###**Pengujian Kedalaman Tree**

####**Kedalaman Tree = 30**
"""

model_depth_30 = RandomForestClassifier(n_estimators=300,
                                        max_depth=30,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_depth_30 = cross_val_score(model_depth_30, X, y, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_depth_30)
print('Rata-rata akurasi :', scores_depth_30.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_depth_30, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Kedalaman Tree = 40**"""

model_depth_40 = RandomForestClassifier(n_estimators=300,
                                        max_depth=40,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_depth_40 = cross_val_score(model_depth_40, X, y, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_depth_40)
print('Rata-rata akurasi :', scores_depth_40.mean())

actual_classes, predicted_classes, _ = cross_val_predict(model_depth_40, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Kedalaman Tree = 50**"""

model_depth_50 = RandomForestClassifier(n_estimators=300,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_depth_50 = cross_val_score(model_depth_50, X, y, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_depth_50)
print('Rata-rata akurasi :', scores_depth_50.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_depth_50, cv, X, y)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""###**Pengujian Jumlah Data**

####**Jumlah Data = 400**
"""

data_400 = df_clean.sample(n=400, random_state=0)
data_400.reset_index(inplace=True)
data_400 = data_400.drop(columns=['index'])
data_400.head()

# Distibusi data perkelas
data_400['Label'].value_counts()

# TF-IDF Data 400
tfidf400 = vectorizer.fit_transform(data_400['review'])
print(tfidf400)

X_400 = tfidf400
y_400 = data_400['Label']
print(X_400.shape, y_400.shape)

model_data_400 = RandomForestClassifier(n_estimators=300,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_data_400 = cross_val_score(model_data_400, X_400, y_400, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_data_400)
print('Rata-rata akurasi :', scores_data_400.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_data_400, cv, X_400, y_400)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Jumlah Data = 500**"""

data_500 = df_clean.sample(n=500, random_state=0)
data_500.reset_index(inplace=True)
data_500 = data_500.drop(columns=['index'])
data_500.head()

# Distibusi data perkelas
data_500['Label'].value_counts()

# TF-IDF Data 500
tfidf500 = vectorizer.fit_transform(data_500['review'])
print(tfidf500)

X_500 = tfidf500
y_500 = data_500['Label']
print(X_500.shape, y_500.shape)

model_data_500 = RandomForestClassifier(n_estimators=300,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_data_500 = cross_val_score(model_data_500, X_500, y_500, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_data_500)
print('Rata-rata akurasi :', scores_data_500.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_data_500, cv, X_500, y_500)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""####**Jumlah Data = 550**"""

data_550 = df_clean.sample(n=550, random_state=0)
data_550.reset_index(inplace=True)
data_550 = data_550.drop(columns=['index'])
data_550.head()

# Distibusi data perkelas
data_550['Label'].value_counts()

# TF-IDF Data 500
tfidf550 = vectorizer.fit_transform(data_550['review'])
print(tfidf550)

X_550 = tfidf550
y_550 = data_550['Label']
print(X_550.shape, y_550.shape)

model_data_550 = RandomForestClassifier(n_estimators=300,
                                        max_depth=50,
                                        random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_data_550 = cross_val_score(model_data_550, X_550, y_550, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_data_550)
print('Rata-rata akurasi :', scores_data_550.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_data_550, cv, X_550, y_550)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])

"""###**Pengujian Algoritma Random Forest**

Gabungan parameter terbaik dari pengujian diatas:


*   Jumlah Tree = 300
*   Kedalaman Tree = 50
*   Jumlah Data = 550
"""

model_final = RandomForestClassifier(n_estimators=300,
                               max_depth=50,
                               random_state=0)
cv = KFold(n_splits=10, random_state=1, shuffle=True)

scores_final = cross_val_score(model_final, X_550, y_550, cv=cv,
                                 scoring=make_scorer(classification_report_with_accuracy_score))

print('Keseluruhan akurasi :\n', scores_final)
print('Rata-rata akurasi :', scores_final.mean())

"""**Confusion Matrix**"""

actual_classes, predicted_classes, _ = cross_val_predict(model_final, cv, X_550, y_550)
plot_confusion_matrix(actual_classes, predicted_classes, [0,1,2])